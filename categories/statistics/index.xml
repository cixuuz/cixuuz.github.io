<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Chen Tong&#39;s Ideas and Writings</title>
    <link>https://cixuuz.github.io/categories/statistics/</link>
    <description>Recent content in Statistics on Chen Tong&#39;s Ideas and Writings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	<atom:link href="https://cixuuz.github.io/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Preicision, Recall, and F-Measure</title>
      <link>https://cixuuz.github.io/post/2016-03-31-precision-recall-fmeasure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cixuuz.github.io/post/2016-03-31-precision-recall-fmeasure/</guid>
      <description>This is one of notes from CS3943/9223 Foundation of Data Science at New York University.
First of all, we have definitions: In pattern recognition and information retrieval with binary classification, precision (also called positive predictive value) is the fraction of retrieved instances that are relevant, while recall (also known as sensitivity) is the fraction of relevant instances that are retrieved. Both precision and recall are therefore based on an understanding and measure of relevance.</description>
    </item>
    
  </channel>
</rss>